{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityavyas/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "import timeit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Display plots inline and change default figure size\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = mnist.train.images, mnist.train.labels\n",
    "test_X, test_y = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_input_dim = train_X.shape[1]\n",
    "nn_output_dim = train_y.shape[1]\n",
    "nn_hdim1 = 256\n",
    "nn_hdim2 = 256\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Define variables\n",
    "def initialize_variables():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, nn_input_dim])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, nn_output_dim])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "#Define weights and biases\n",
    "def initialize_weights_biases():\n",
    "    np.random.seed(0)\n",
    "    W1 = tf.Variable(tf.random_normal(shape=[nn_input_dim, nn_hdim1]))\n",
    "    b1 = tf.Variable(tf.zeros(shape=[1, nn_hdim1]))\n",
    "    \n",
    "    W2 = tf.Variable(tf.random_normal(shape=[nn_hdim1, nn_hdim2]))\n",
    "    b2 = tf.Variable(tf.zeros(shape=[1, nn_hdim2]))\n",
    "    \n",
    "    W3 = tf.Variable(tf.random_normal(shape=[nn_hdim2, nn_output_dim]))\n",
    "    b3 = tf.Variable(tf.zeros(shape=[1, nn_output_dim])) \n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(train_X, train_y, num_rounds=10000):\n",
    "    \n",
    "    X, y = initialize_variables()\n",
    "    W1, b1, W2, b2, W3, b3 = initialize_weights_biases()\n",
    "    \n",
    "    #Forward Propogation\n",
    "    z1 = tf.matmul(X, W1) + b1\n",
    "    a1 = tf.nn.relu(z1)\n",
    "    \n",
    "    z2 = tf.matmul(a1, W2) + b2\n",
    "    a2 = tf.nn.relu(z2)\n",
    "    \n",
    "    yhat = tf.matmul(a2, W3) + b3\n",
    "    predict = tf.argmax(yhat, axis=1)\n",
    "    \n",
    "    #Back-Propogation\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    updates = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "    \n",
    "    #Intialize Session\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(15):\n",
    "\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([updates, cost], feed_dict={X: batch_x,\n",
    "                                                              y: batch_y})\n",
    "                avg_cost += c / total_batch\n",
    "\n",
    "            if epoch % display_step == 0:\n",
    "                print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                    \"{:.9f}\".format(avg_cost)\n",
    "        print \"Optimization Finished!\"\n",
    "\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(predict, tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print \"Accuracy:\", accuracy.eval({X: test_X, y: test_y}, session=sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 170.992474618\n",
      "Epoch: 0002 cost= 41.497047236\n",
      "Epoch: 0003 cost= 26.542450598\n",
      "Epoch: 0004 cost= 19.177371437\n",
      "Epoch: 0005 cost= 13.361963507\n",
      "Epoch: 0006 cost= 9.944470229\n",
      "Epoch: 0007 cost= 7.515627766\n",
      "Epoch: 0008 cost= 5.922122079\n",
      "Epoch: 0009 cost= 4.399098127\n",
      "Epoch: 0010 cost= 3.268238079\n",
      "Epoch: 0011 cost= 2.707098489\n",
      "Epoch: 0012 cost= 2.001017162\n",
      "Epoch: 0013 cost= 1.441404285\n",
      "Epoch: 0014 cost= 1.109690248\n",
      "Epoch: 0015 cost= 0.942752068\n",
      "Optimization Finished!\n",
      "Accuracy: 0.943\n"
     ]
    }
   ],
   "source": [
    "neural_network_model(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
