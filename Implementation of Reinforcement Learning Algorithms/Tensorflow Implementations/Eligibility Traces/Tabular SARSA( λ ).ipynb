{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\")\n",
    "\n",
    "import gym\n",
    "import plotting\n",
    "from lib.envs.gridworld import GridworldEnv\n",
    "import itertools\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = GridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T  o  o  o\n",
      "o  o  o  o\n",
      "o  o  x  o\n",
      "o  o  o  T\n",
      "[4, 4]\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create an initial epsilon soft policy\n",
    "def epsilon_greedy_policy(Q, epsilon, state, nA):\n",
    "    A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "    best_action = np.argmax(Q[state])\n",
    "    A[best_action] += (1.0 - epsilon)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def online_sarsa_lambda(env, num_episodes, discount=1.0, epsilon=0.1, alpha=0.5, lbda=0.9, debug=False):\n",
    "    \n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n, dtype=float))\n",
    "    \n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        \n",
    "        if debug:\n",
    "            if i_episode % 1000 == 0:\n",
    "                print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes))\n",
    "                \n",
    "        E = {key:np.zeros(4, dtype=int) for key in np.arange(16)}\n",
    "        state = env.reset()\n",
    "        action_probs = epsilon_greedy_policy(Q, epsilon, state, env.nA)\n",
    "        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "        for t in itertools.count():\n",
    "            next_state, reward, end, _ = env.step(action)\n",
    "            \n",
    "            next_action_probs = epsilon_greedy_policy(Q, epsilon, next_state, env.nA)\n",
    "            next_action = np.random.choice(np.arange(len(next_action_probs)), p=next_action_probs)\n",
    "            \n",
    "            delta = reward + discount*Q[next_state][next_action] - Q[state][action]\n",
    "            E[state][action] += 1\n",
    "            \n",
    "            for s in E.keys():\n",
    "                for a in E[s]:\n",
    "                    Q[s][a] += alpha*delta*E[s][a]\n",
    "                    E[s][a] = discount*lbda*E[s][a]\n",
    "                    \n",
    "            if end:\n",
    "                break\n",
    "                \n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            \n",
    "    return Q    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000/10000.\n",
      "Episode 2000/10000.\n",
      "Episode 3000/10000.\n",
      "Episode 4000/10000.\n",
      "Episode 5000/10000.\n",
      "Episode 6000/10000.\n",
      "Episode 7000/10000.\n",
      "Episode 8000/10000.\n",
      "Episode 9000/10000.\n",
      "Episode 10000/10000.\n"
     ]
    }
   ],
   "source": [
    "Q = online_sarsa_lambda(env, num_episodes=10000, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {0: array([ 0.,  0.,  0.,  0.]),\n",
       "             1: array([-1.00334249, -3.24963391, -3.42187521,  0.        ]),\n",
       "             2: array([-3.24970931, -4.25767707, -2.2578125 , -2.24963379]),\n",
       "             3: array([-4.26403069, -4.27333278, -4.0234375 , -3.2578125 ]),\n",
       "             4: array([-1.        , -2.4777315 , -5.27484555, -1.5       ]),\n",
       "             5: array([-1.00083547, -4.00062179, -3.8125    , -2.953125  ]),\n",
       "             6: array([-3.24962602, -4.38325268, -3.90625   , -2.99707031]),\n",
       "             7: array([-4.40579551, -4.10019576, -3.76989174, -3.0234375 ]),\n",
       "             8: array([-2.00004227, -4.36602511, -4.6146492 , -6.06161064]),\n",
       "             9: array([-3.96138778, -3.30563219, -3.8996314 , -5.78905885]),\n",
       "             10: array([-3.93345338, -1.75675408, -4.1645967 , -8.73046327]),\n",
       "             11: array([-4.069583  , -1.75012255, -0.75      , -3.00000286]),\n",
       "             12: array([-3.06552368, -4.15733446, -5.31050544, -5.13733019]),\n",
       "             13: array([-4.69517263, -2.05221652, -4.46802267, -5.26098633]),\n",
       "             14: array([-3.91992161, -1.        , -2.        , -3.08203125]),\n",
       "             15: array([ 0.,  0.,  0.,  0.])})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Optimal Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T  o  o  o\n",
      "o  o  o  o\n",
      "x  o  o  o\n",
      "o  o  o  T\n",
      "None\n",
      "#################################\n",
      "T  o  o  o\n",
      "x  o  o  o\n",
      "o  o  o  o\n",
      "o  o  o  T\n",
      "None\n",
      "#################################\n",
      "x  o  o  o\n",
      "o  o  o  o\n",
      "o  o  o  o\n",
      "o  o  o  T\n",
      "None\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print env.render()\n",
    "print '#################################'\n",
    "while(True):\n",
    "    action = np.argmax(Q[state])\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    state = next_state\n",
    "    \n",
    "    print env.render()\n",
    "    print '#################################'\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
