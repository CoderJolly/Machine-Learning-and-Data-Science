{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE, RFECV, SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print(\"############# Read Data #############\")\n",
    "    \n",
    "    train_orig = pd.read_csv('../input/train.csv')\n",
    "    test_orig = pd.read_csv('../input/test.csv')\n",
    "    \n",
    "    return train_orig, test_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8116d0ae842574c6624cbc901d06b15db3e7320"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b911806c5b2f350dad6d4738782e2682119ad848"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_orig, test_orig, scale_features = True):\n",
    "    print(\"############# Preprocess Data #############\")\n",
    "    \n",
    "    train, test = train_orig.copy(), test_orig.copy()\n",
    "    train, target = train.drop(['target', 'id'], 1), train['target']\n",
    "    test = test.drop('id', 1)\n",
    "    \n",
    "    if scale_features:\n",
    "        scaler = StandardScaler()\n",
    "        train = pd.DataFrame(scaler.fit_transform(train))\n",
    "        test = pd.DataFrame(scaler.fit_transform(test))\n",
    "        \n",
    "    return train, test, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(train, target):\n",
    "    print(\"############# SMOTE #############\")\n",
    "    \n",
    "    columns = train.columns\n",
    "    sm = SMOTE(sampling_strategy = 'minority')\n",
    "    train, target = sm.fit_resample(train, target)\n",
    "    train = pd.DataFrame(train)\n",
    "    target = pd.DataFrame(target)\n",
    "    train.columns = columns\n",
    "    return train, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(train, test, add_pca = False, add_kmeans = False):\n",
    "    print(\"############# Feature Engineering #############\")\n",
    "    \n",
    "    train['sum'] = train.sum(axis = 1)\n",
    "    train['mean'] = train.mean(axis = 1)\n",
    "    train['std'] = train.std(axis = 1)\n",
    "    train['min'] = train.min(axis = 1)\n",
    "    train['max'] = train.max(axis = 1)\n",
    "    train['var'] = train.var(axis = 1)\n",
    "    train['skew'] = train.skew(axis = 1)\n",
    "    train['kurtosis'] = train.kurtosis(axis = 1)\n",
    "    \n",
    "    \n",
    "    test['sum'] = test.sum(axis = 1)\n",
    "    test['mean'] = test.mean(axis = 1)\n",
    "    test['std'] = test.std(axis = 1)\n",
    "    test['min'] = test.min(axis = 1)\n",
    "    test['max'] = test.max(axis = 1)\n",
    "    test['var'] = test.var(axis = 1)\n",
    "    test['skew'] = test.skew(axis = 1)\n",
    "    test['kurtosis'] = test.kurtosis(axis = 1)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking the feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(atrain['3'], bw = 0.5, label = \"train\")\n",
    "# sns.kdeplot(test['3'], bw = 0.5, label = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(train.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c52bc3b50ca1895c60ae9df6b3c5137fcbfeda3"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(data, target, shuffle = False, seed = 42):\n",
    "    \n",
    "    # Gather real features\n",
    "    train_features = data.columns\n",
    "    \n",
    "    # Go over fold and keep track of CV score (train and valid) and feature importances\n",
    "    # Shuffle target if required\n",
    "    y = target.copy()\n",
    "    if shuffle:\n",
    "        # Here you could as well use a binomial distribution\n",
    "        y = target.copy().sample(frac = 1.0)\n",
    "    \n",
    "    # Fit LightGBM in RF mode, yes it's quicker than sklearn RandomForest\n",
    "    dtrain = lgb.Dataset(data, y, free_raw_data = False, silent = True)\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'rf',\n",
    "        'subsample': 0.623,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'num_leaves': 127,\n",
    "        'max_depth': 6,\n",
    "        'seed': seed,\n",
    "        'bagging_freq': 1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    clf = lgb.train(params = lgb_params, train_set = dtrain, num_boost_round = 200)\n",
    "\n",
    "    # Get feature importances\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df[\"feature\"] = list(train_features)\n",
    "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type = 'gain')\n",
    "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type = 'split')\n",
    "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(data))\n",
    "    return imp_df\n",
    "\n",
    "def get_feature_scores(true_df, noise_df):\n",
    "    \n",
    "    correlation_scores = []\n",
    "    for feature in true_df['feature'].unique():\n",
    "        \n",
    "        # Gain score\n",
    "        f_null_imps = noise_df.loc[noise_df['feature'] == feature, 'importance_gain'].values\n",
    "        f_act_imps = true_df.loc[true_df['feature'] == feature, 'importance_gain'].values\n",
    "        gain_score = 100 * (f_null_imps < f_act_imps).sum() / f_null_imps.size\n",
    "        \n",
    "        # Split score\n",
    "        f_null_imps = noise_df.loc[noise_df['feature'] == feature, 'importance_split'].values\n",
    "        f_act_imps = true_df.loc[true_df['feature'] == feature, 'importance_split'].values\n",
    "        split_score = 100 * (f_null_imps < f_act_imps).sum() / f_null_imps.size\n",
    "        \n",
    "        correlation_scores.append((feature, split_score, gain_score))\n",
    "    return correlation_scores\n",
    "\n",
    "def get_imp_features_using_thresholding(correlation_scores, data, target):\n",
    "    \n",
    "    # Fit LightGBM\n",
    "    def score_feature_selection(data, train_features, target):\n",
    "        dtrain = lgb.Dataset(data[train_features], target, free_raw_data = False, silent = True)\n",
    "        lgb_params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate': .1,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': 5,\n",
    "            'seed': 13,\n",
    "            'n_jobs': 4,\n",
    "            'min_split_gain': .00001,\n",
    "            'reg_alpha': .00001,\n",
    "            'reg_lambda': .00001,\n",
    "            'metric': 'auc'\n",
    "        }\n",
    "\n",
    "        # Fit the model\n",
    "        hist = lgb.cv(\n",
    "            params = lgb_params, \n",
    "            train_set = dtrain, \n",
    "            num_boost_round = 2000,\n",
    "            nfold = 5,\n",
    "            stratified = True,\n",
    "            shuffle = True,\n",
    "            early_stopping_rounds = 50,\n",
    "            verbose_eval = 0,\n",
    "            seed = 17\n",
    "        )\n",
    "\n",
    "        # Get the last mean / std values \n",
    "        return hist['auc-mean'][-1], hist['auc-stdv'][-1]\n",
    "    \n",
    "    best_features_gain = []\n",
    "    best_features_split = []\n",
    "    max_gain_ = -10000\n",
    "    max_split_ = -10000\n",
    "    print('\\n')\n",
    "    for threshold in [0, 10, 20, 30 , 40, 50 ,60 , 70, 80 , 90, 95, 99]:\n",
    "        split_feats = [_f for _f, _score, _ in correlation_scores if _score >= threshold]\n",
    "        gain_feats = [_f for _f, _, _score in correlation_scores if _score >= threshold]\n",
    "        \n",
    "        print('Threshold %3d' % threshold)\n",
    "        split_results = score_feature_selection(data = data, train_features = split_feats, target = target)\n",
    "        gain_results = score_feature_selection(data = data, train_features = gain_feats, target = target)\n",
    "        \n",
    "        if gain_results[0] > max_gain_:\n",
    "            best_features_gain = gain_feats\n",
    "            max_gain_ = gain_results[0]\n",
    "            \n",
    "        if split_results[0] > max_split_:\n",
    "            best_features_split = split_feats\n",
    "            max_split_ = split_results[0]\n",
    "    \n",
    "    return best_features_gain\n",
    "\n",
    "def feature_selector(train, target, best_params = None, num_features = 100, num_permutations = 100, method = \"rfe\", model_name = \"rforest\"):\n",
    "    print(\"############# Feature Selection #############\")\n",
    "    \n",
    "    if model_name == 'logistic':\n",
    "        model = LogisticRegression(solver = \"liblinear\", penalty = 'l1')\n",
    "    elif model_name == \"rforest\":\n",
    "        model = RandomForestClassifier(n_estimators = 500, max_depth = 5, random_state = 42, class_weight = \"balanced\")\n",
    "    elif model_name == \"xgb\":\n",
    "        model = xgb.XGBClassifier(n_estimators = 500, random_state = 42, max_depth = 5)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    if method == \"rfe\":\n",
    "        selector = RFE(model, num_features)\n",
    "        selector.fit(train, target.values.ravel())\n",
    "        selected_features = train.columns[selector.get_support()]\n",
    "    elif method == \"boruta\":\n",
    "        boruta_model = RandomForestClassifier(max_depth = 5, random_state = 42, class_weight = \"balanced\", n_jobs = -1)\n",
    "        boruta = BorutaPy(boruta_model, n_estimators = 'auto', verbose = 5)\n",
    "        boruta.fit(train.values, target.values)\n",
    "        selected_features = train.columns[boruta.support_]\n",
    "    elif method == \"lasso\":\n",
    "        lasso = Lasso(alpha = 0.0335, selection = \"random\", tol = 0.01, random_state = 42)\n",
    "        model = SelectFromModel(lasso, threshold = -np.inf, max_features = num_features)\n",
    "        model.fit(train, target)\n",
    "        selected_features = train.columns[model.get_support()]\n",
    "    elif method == 'null_importances':\n",
    "        true_imp = get_feature_importances(data = train, target = target)\n",
    "        \n",
    "        # Calculate the permutation null distribution\n",
    "        num_permutations = num_permutations\n",
    "        null_imp_df = pd.DataFrame()\n",
    "        for i in range(num_permutations):\n",
    "            \n",
    "            print(i, end = \" \")\n",
    "            \n",
    "            # Get current run importances\n",
    "            imp_df = get_feature_importances(data = train, target = target, shuffle = True)\n",
    "            imp_df['run'] = i + 1 \n",
    "            \n",
    "            # Concat the latest importances with the old ones\n",
    "            null_imp_df = pd.concat([null_imp_df, imp_df], axis = 0)\n",
    "            \n",
    "        # Get feature scores\n",
    "        scores = get_feature_scores(true_df = true_imp, noise_df = null_imp_df)\n",
    "        selected_features = get_imp_features_using_thresholding(correlation_scores = scores, \n",
    "                                                              data = train, \n",
    "                                                              target = target)\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train, target, selected_features = None, cv = 5, model_name = \"logistic\"):\n",
    "    print(\"############# Grid Search #############\")\n",
    "    \n",
    "    if selected_features is None:\n",
    "        selected_features = train.columns\n",
    "        \n",
    "    if model_name == \"logistic\":\n",
    "        model = LogisticRegression(random_state = 42)\n",
    "        param_grid = {\n",
    "            'class_weight' : ['balanced'], \n",
    "            'penalty' : ['l1'],\n",
    "            'solver': ['liblinear'],\n",
    "            'C' : np.arange(0.01, 0.1, 0.01)\n",
    "        }\n",
    "    elif model_name == \"svm\":\n",
    "        model = SVC(random_state = 42)\n",
    "        param_grid = {\n",
    "            'C': np.arange(0.02, 0.03, 0.001),\n",
    "            'class_weight': ['balanced'],\n",
    "            'gamma': ['auto'],\n",
    "            'probability': [True],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "        }\n",
    "    elif model_name == \"lasso\":\n",
    "        model = Lasso(random_state = 42)\n",
    "        param_grid = {\n",
    "            'alpha' : [0.022, 0.021, 0.02, 0.019, 0.023, 0.024, 0.025, 0.026, 0.027, 0.029, 0.031],\n",
    "            'tol'   : [0.0013, 0.0014, 0.001, 0.0015, 0.0011, 0.0012, 0.0016, 0.0017]\n",
    "        }\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    grid = GridSearchCV(estimator = model, cv = cv, param_grid = param_grid , scoring = 'roc_auc', verbose = 1, n_jobs = -1)\n",
    "    grid.fit(train[selected_features], target)\n",
    "\n",
    "    print(\"Best Score:\" + str(grid.best_score_))\n",
    "    print(\"Best Parameters: \" + str(grid.best_params_))\n",
    "\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb070ce90aa759bd3adff0c2e662c5c0ab7396b8"
   },
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "11755e30790985cbc6183033a0bafb83eed8159c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(train, \n",
    "                target, \n",
    "                test, \n",
    "                best_params, \n",
    "                selected_features = None, \n",
    "                n_folds = 11, \n",
    "                n_repeats = 15,\n",
    "                stratify = True,\n",
    "                model_name = 'logistic'):\n",
    "    print(\"############# Train Model #############\")\n",
    "    \n",
    "    if selected_features is None:\n",
    "        selected_features = train.columns\n",
    "    \n",
    "    train = train[selected_features]\n",
    "    test = test[selected_features]\n",
    "        \n",
    "    train_predictions = np.zeros((train.shape[0], 1))\n",
    "    test_predictions = np.zeros((test.shape[0], 1))\n",
    "    \n",
    "    if stratify:\n",
    "        cv = RepeatedStratifiedKFold(n_splits = n_folds, random_state = 420, n_repeats = n_repeats)\n",
    "    else:\n",
    "        cv = RepeatedKFold(n_splits = n_folds, random_state = 420, n_repeats = n_repeats)\n",
    "    cv.get_n_splits(train, target)\n",
    "\n",
    "    cv_scores = []\n",
    "    fold = 1\n",
    "    coefs = []\n",
    "    for train_idx, valid_idx in cv.split(train, target):\n",
    "        xtrain, xvalid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        ytrain, yvalid = target.iloc[train_idx], target.iloc[valid_idx]\n",
    "        \n",
    "        if model_name == \"logistic\":\n",
    "            model = LogisticRegression(**best_params)\n",
    "        elif model_name == \"svm\":\n",
    "            model = SVC(**best_params)\n",
    "        elif model_name == \"lasso\":\n",
    "            model = Lasso(**best_params) if best_params else Lasso()\n",
    "        elif model_name == \"ridge\":\n",
    "            model = Ridge(**best_params)\n",
    "        else:\n",
    "            return\n",
    "        model.fit(xtrain, ytrain.values.ravel())\n",
    "        coefs.append(model.coef_)\n",
    "        \n",
    "        if model_name in ['logistic']:\n",
    "            valid_preds = model.predict_proba(xvalid)[:, 1]\n",
    "        else:\n",
    "            valid_preds = model.predict(xvalid).clip(0, 1)\n",
    "        train_predictions[valid_idx] = valid_preds.reshape(-1, 1)\n",
    "\n",
    "        scr = roc_auc_score(yvalid.values, valid_preds)\n",
    "        cv_scores.append(scr)\n",
    "        print(\"Fold = {}. AUC = {}.\".format(fold, scr))\n",
    "        \n",
    "        if model_name in ['logistic']:\n",
    "            test_preds = model.predict_proba(test)[:, 1]\n",
    "        else:\n",
    "            test_preds = model.predict(test).clip(0, 1)\n",
    "        test_predictions += test_preds.reshape(-1, 1)\n",
    "        fold += 1\n",
    "    test_predictions = test_predictions * 1./(n_folds*n_repeats)\n",
    "    print(\"Mean Score: {}. Std Dev: {}\".format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    return test_predictions, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Read Data #############\n",
      "############# Preprocess Data #############\n",
      "############# Feature Engineering #############\n"
     ]
    }
   ],
   "source": [
    "# Read the data and scale features\n",
    "train_orig, test_orig = read_data()\n",
    "\n",
    "# Preprocess data\n",
    "train, test, target = preprocess_data(train_orig, test_orig, scale_features = False)\n",
    "\n",
    "# Feature engineering\n",
    "train, test = create_features(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find different sets of best features\n",
    "# best_features_rfe_rforest = feature_selector(train, target, method = \"rfe\", num_features = 30, model_name = \"rforest\")\n",
    "# best_features_rfe_xgb = feature_selector(train, target, method = \"rfe\", num_features = 30, model_name = 'xgb')\n",
    "# best_features_rfe_logistic = feature_selector(train, target, method = \"rfe\", num_features = 30, model_name = 'logistic')\n",
    "# best_features_boruta = feature_selector(train, target, method = \"boruta\")\n",
    "# best_features_null_importances = feature_selector(train, target, method = \"null_importances\", num_permutations = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Feature Selection #############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['33', '65', '73', '80', '91', '117', '199', '217', '226', '295'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_lasso = feature_selector(train, target, method = \"lasso\", num_features = 10)\n",
    "best_features_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_features_rfe_logistic = ['33', '42', '43', '65', '67', '69', '73', '82', '90', '91', '95', '101',\n",
    "#        '108', '117', '130', '132', '134', '149', '165', '168', '183', '199',\n",
    "#        '217', '239', '258', '259', '261', '272', '293', '295']\n",
    "\n",
    "# best_features_rfe_rforest = ['33', '42', '43', '65', '67', '69', '73', '82', '90', '91', '95', '101',\n",
    "#        '108', '117', '130', '132', '134', '149', '165', '168', '183', '199',\n",
    "#        '217', '239', '258', '259', '261', '272', '293', '295']\n",
    "\n",
    "# best_features_rfe_xgb = ['9', '16', '17', '30', '33', '35', '48', '51', '65', '91', '100', '102',\n",
    "#        '106', '117', '118', '131', '134', '157', '214', '217', '219', '237',\n",
    "#        '249', '250', '268', '282', 'sum', 'std', 'min', 'var']\n",
    "\n",
    "# best_features_boruta = ['17', '24', '33', '65', '80', '91', '117', '217', 'sum']\n",
    "\n",
    "# best_features_null_importances = ['7',\n",
    "#  '9',\n",
    "#  '16',\n",
    "#  '24',\n",
    "#  '33',\n",
    "#  '43',\n",
    "#  '45',\n",
    "#  '48',\n",
    "#  '50',\n",
    "#  '65',\n",
    "#  '70',\n",
    "#  '73',\n",
    "#  '82',\n",
    "#  '83',\n",
    "#  '91',\n",
    "#  '101',\n",
    "#  '104',\n",
    "#  '108',\n",
    "#  '117',\n",
    "#  '127',\n",
    "#  '131',\n",
    "#  '133',\n",
    "#  '141',\n",
    "#  '147',\n",
    "#  '151',\n",
    "#  '157',\n",
    "#  '164',\n",
    "#  '165',\n",
    "#  '176',\n",
    "#  '179',\n",
    "#  '183',\n",
    "#  '189',\n",
    "#  '194',\n",
    "#  '198',\n",
    "#  '199',\n",
    "#  '211',\n",
    "#  '217',\n",
    "#  '225',\n",
    "#  '226',\n",
    "#  '227',\n",
    "#  '258',\n",
    "#  '295',\n",
    "#  '298',\n",
    "#  'sum',\n",
    "#  'mean',\n",
    "#  'min',\n",
    "#  'max',\n",
    "#  'var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_features_rfe_rforest = ['16', '17', '24', '30', '33', '39', '63', '65', '70', '73', '82', '91', \n",
    "#                              '101', '117', '164', '183', '189', '194', '199', '201', '217', '230', '231', \n",
    "#                              '237', '272', '295']\n",
    "# best_features_rfe_rforest = [ '65', '33', '15', '69', '73', '79', '91', '82', '46', '201', '217', '295', '289', \n",
    "#                              '258', '249', '281', '285', '164', '117', '100', '198', '101', '237', '165', '115', \n",
    "#                              '199', '146', '119', '134']\n",
    "\n",
    "# best_features_rfe_rforest = ['33', '65']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best params\n",
    "# best_params_logistic = grid_search(train, target, cv = 3, selected_features = best_features, model_name = 'logistic')\n",
    "# best_params_svm = grid_search(train, target, cv = 3, selected_features = best_features, model_name = 'svm')\n",
    "# best_params_lasso = grid_search(train, target, cv = 10, selected_features = best_features, model_name = 'lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_logistic = {'C': 0.2, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'random_state': 42}\n",
    "# predictions_logistic = train_model(train = train, \n",
    "#                                    target = target, \n",
    "#                                    test = test, \n",
    "#                                    best_params = best_params_logistic, \n",
    "#                                    n_folds = 10, \n",
    "#                                    n_repeats = 3, \n",
    "#                                    selected_features = best_features_rfe_rforest,\n",
    "#                                    model_name = \"logistic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_svm = {'C': 0.007, 'class_weight': 'balanced', 'kernel': 'rbf', 'gamma': 'auto'}\n",
    "# predictions_svm = train_model(train = train, \n",
    "#                             target = target, \n",
    "#                             test = test, \n",
    "#                             best_params = best_params_svm, \n",
    "#                             n_folds = 10, \n",
    "#                             n_repeats = 3, \n",
    "#                             selected_features = None,\n",
    "#                             model_name = \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Train Model #############\n",
      "Fold = 1. AUC = 0.8125.\n",
      "Fold = 2. AUC = 0.8402777777777778.\n",
      "Fold = 3. AUC = 0.875.\n",
      "Fold = 4. AUC = 0.8888888888888888.\n",
      "Fold = 5. AUC = 0.9027777777777778.\n",
      "Fold = 6. AUC = 0.861111111111111.\n",
      "Fold = 7. AUC = 0.7222222222222222.\n",
      "Fold = 8. AUC = 0.8611111111111112.\n",
      "Fold = 9. AUC = 0.923611111111111.\n",
      "Fold = 10. AUC = 0.8402777777777779.\n",
      "Fold = 11. AUC = 0.9166666666666667.\n",
      "Fold = 12. AUC = 0.7013888888888888.\n",
      "Fold = 13. AUC = 0.8750000000000001.\n",
      "Fold = 14. AUC = 0.8888888888888888.\n",
      "Fold = 15. AUC = 0.9791666666666667.\n",
      "Fold = 16. AUC = 0.8194444444444445.\n",
      "Fold = 17. AUC = 0.8958333333333333.\n",
      "Fold = 18. AUC = 0.8819444444444445.\n",
      "Fold = 19. AUC = 0.8125.\n",
      "Fold = 20. AUC = 0.9097222222222222.\n",
      "Fold = 21. AUC = 0.9305555555555556.\n",
      "Fold = 22. AUC = 0.8402777777777778.\n",
      "Fold = 23. AUC = 0.9375.\n",
      "Fold = 24. AUC = 0.7847222222222222.\n",
      "Fold = 25. AUC = 0.9652777777777778.\n",
      "Fold = 26. AUC = 0.7430555555555556.\n",
      "Fold = 27. AUC = 0.9583333333333333.\n",
      "Fold = 28. AUC = 0.6736111111111112.\n",
      "Fold = 29. AUC = 0.8125.\n",
      "Fold = 30. AUC = 0.9375.\n",
      "Mean Score: 0.8597222222222223. Std Dev: 0.07641834448930175\n"
     ]
    }
   ],
   "source": [
    "best_params_lasso = {'alpha': 0.0445, 'tol': 0.01, 'selection': 'random', 'random_state': 42, 'max_iter': 1000}\n",
    "predictions_lasso_2, coefs = train_model(train = train, \n",
    "                                        target = target, \n",
    "                                        test = test, \n",
    "                                        best_params = best_params_lasso, \n",
    "                                        n_folds = 10, \n",
    "                                        n_repeats = 3,\n",
    "                                        stratify = True,\n",
    "                                        selected_features = best_features_lasso,\n",
    "                                        model_name = \"lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_lasso_1, coefs = train_model(train = train, \n",
    "#                                         target = target, \n",
    "#                                         test = test, \n",
    "#                                         best_params = best_params_lasso, \n",
    "#                                         n_folds = 10, \n",
    "#                                         n_repeats = 3,\n",
    "#                                         stratify = True,\n",
    "#                                         selected_features = best_features_rfe_logistic,\n",
    "#                                         model_name = \"lasso\")\n",
    "\n",
    "# predictions_lasso_2, coefs = train_model(train = train, \n",
    "#                                         target = target, \n",
    "#                                         test = test, \n",
    "#                                         best_params = best_params_lasso, \n",
    "#                                         n_folds = 10, \n",
    "#                                         n_repeats = 3,\n",
    "#                                         stratify = True,\n",
    "#                                         selected_features = best_features_rfe_rforest,\n",
    "#                                         model_name = \"lasso\")\n",
    "\n",
    "# predictions_lasso_3, coefs = train_model(train = train, \n",
    "#                                         target = target, \n",
    "#                                         test = test, \n",
    "#                                         best_params = best_params_lasso, \n",
    "#                                         n_folds = 10, \n",
    "#                                         n_repeats = 3,\n",
    "#                                         stratify = True,\n",
    "#                                         selected_features = best_features_rfe_xgb,\n",
    "#                                         model_name = \"lasso\")\n",
    "\n",
    "# predictions_lasso_4, coefs = train_model(train = train, \n",
    "#                                         target = target, \n",
    "#                                         test = test, \n",
    "#                                         best_params = best_params_lasso, \n",
    "#                                         n_folds = 10, \n",
    "#                                         n_repeats = 3,\n",
    "#                                         stratify = True,\n",
    "#                                         selected_features = best_features_boruta,\n",
    "#                                         model_name = \"lasso\")\n",
    "\n",
    "# predictions_lasso_5, coefs = train_model(train = train, \n",
    "#                                         target = target, \n",
    "#                                         test = test, \n",
    "#                                         best_params = best_params_lasso, \n",
    "#                                         n_folds = 10, \n",
    "#                                         n_repeats = 3,\n",
    "#                                         stratify = True,\n",
    "#                                         selected_features = best_features_null_importances,\n",
    "#                                         model_name = \"lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_lasso = np.mean([predictions_lasso_1, predictions_lasso_2, predictions_lasso_3, predictions_lasso_4, predictions_lasso_5], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.754301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.719607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.647965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.705634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.602006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>255</td>\n",
       "      <td>0.536024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>0.569001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>257</td>\n",
       "      <td>0.371922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>258</td>\n",
       "      <td>0.793336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>259</td>\n",
       "      <td>0.418175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.754301\n",
       "1  251  0.719607\n",
       "2  252  0.647965\n",
       "3  253  0.705634\n",
       "4  254  0.602006\n",
       "5  255  0.536024\n",
       "6  256  0.569001\n",
       "7  257  0.371922\n",
       "8  258  0.793336\n",
       "9  259  0.418175"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "submit[\"target\"] = predictions_lasso_2\n",
    "submit.to_csv(\"submission.csv\", index = False)\n",
    "submit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
